\documentclass{prosper}%[pdf,azure,slideColor,colorBG]{prosper}

\usepackage{graphicx} 
\usepackage{graphics}
\usepackage{rotating}
\usepackage{verbatim}

\usepackage{epsfig}

\newcommand{\quiz}[1]{{\begin{flushright}\small\tt\blue #1 \end{flushright}}}

\newcommand{\egk}{\mbox{$\epsilon$}}
\newcommand{\enfa}{{$\epsilon$-NFA}}
\newcommand{\sg}{{\mbox{$\Sigma$}}}

\begin{document}

\begin{slide}{CPS615 - Theory of Computation}
\begin{description}
\item[Instructor:]  Marcus Santos
\item[Lectures:] Weds. 14:00 to 16:00, Fri. 12:00 to 13:00
\item[Laboratory:] Labs start in the week of January 22. See your schedule. 
\item[In Person Office Hours:] Fri. 13:00 to 14:00 in VIC 741
\item [Virtual Office Hours:] Mon 9:00 to 10:00 @ Google Hangouts (m3santos@ryerson.ca)
\item[Online learning tools:] D2L, Gradiance (free web-based tool)
\end{description}
\end{slide}

\begin{slide}{Agenda}
\begin{itemize}
\item Meet Marcus Santos: background,   experience, and interests  (related and unrelated to what we will learn in this course) 
\item Meet You (Homework Assignment 1 - Part 1)
\item What I expect from you. Let's have a look at our Course Outline/Course Management Form
\item What do you expect from me? 
\item Theory of computation: why study it, what is it, let's get started on this.
\end{itemize}
%\quiz{quiz}
\end{slide}



\begin{slide}{About this course}
\begin{itemize}
\item In this course we study the theory of what can be computed and what cannot.
\item We sketch theoretical frameworks  that can inform us the design of programs to solve a wide variety of problems.
\item But why bother with theory? Why we don't just skip ahead and write the programs that we need?
\end{itemize}
Let's see if we can provide a convincing answer to these questions.
\end{slide}

\begin{comment}
\begin{slide}{Programming in the 1840's}
The first algorithm, by Ada Lovelace, for computing Bernoulli numbers in the Analytical Engine.
\begin{center}
\includegraphics[scale=.4]{figures/adascode.eps}
\end{center}

\end{slide}
\begin{slide}{IBM 7090 Programming in the 1950's}
\begin{minipage}{7cm}
\begin{center}
\includegraphics[scale=.4]{figures/ibm7090code.eps}
\end{center}
\end{minipage}
\begin{minipage}{4cm}
A program for computing a simple quadratic equation $ax^2+bx+c$.
\end{minipage}
\end{slide}

\begin{slide}{Programming in the 1970's (IBM 360)}

Using the OS/360 JCL (Job Control Language)
\begin{center}
\includegraphics[scale=.4]{figures/ibm360code.eps}
\end{center}

\end{slide}


\begin{slide}{Programming in the early 2000's}
\begin{center}
\includegraphics[scale=.6]{figures/javacode.eps}
\end{center}
\end{slide}

\begin{slide}{ "Nothing is permanent except change" }
\begin{itemize}
\item Programmers of today can't read code from the 50's.	
\item Programmers of the early days could never have imagined what a program today would look like.
\item In view of that kind of change, what is the end (aim) of the science of computing?
\item Is it about attempting to envision the details of tomorrow's technologies or tomorrow's programming fashion {\em du jour}?
\end{itemize}
\end{slide}
\end{comment}

\begin{slide}{Theory -- why study it}
\begin{itemize}
\item  Because  there are mathematical properties, both of problems and of algorithms for solving problems, that are independent of the technology or the programming fashion {\em en vogue} today.

\item Most of this theory is from the 70's. But it is still useful for two major reasons:
\begin{itemize}
\item It provides a set of (hardware independent) {\blue abstract structures}  that are useful for solving certain classes of problems.
\item It defines limits to what can be computed, regardless of processor speed or memory size.
\end{itemize}
\item Our focus will be on analyzing problems, rather than comparing solutions to problems. Our goal is to discover fundamental properties intrinsic to the problems themselves.
\end{itemize}
\end{slide}

\begin{comment}
\begin{slide}{\large Automata, Formal Languages, and Computation}
%{\em Automata Theory}: the study of computing or "machines"
\begin{itemize}
\item 1843: Charles Babbage \& Ada Lovelace, the Analytical Machine and the first ``Algorithm''.
\item 1930's: Turing aimed to describe where lies the boundary separating what could and could not be computed.
\item 40's: simpler machines ({\blue finite automata}) proposed to model brain function.
\item 50's: Noam Chomsky begins studying {\blue generative grammars} (they are not machines, but closely relate to finite automata). 
\item 1969: S. Cook extended Turing's study and defined where lies the line dividing   problems that  computers can  effectively solve and those that  computers would hopelessly take too much time to solve. 
\end{itemize}
\end{slide}
\end{comment}


\begin{slide}{Abstractions: Finite State Machines}
\begin{itemize}
\item There are many systems that are at all times in one of a finite number of ``states''.
\item A state is a relevant portion of a system's history.
\item Systems are carefully designed so that they remember what is important and forget what is not.
\end{itemize}
Example of a finite automaton modelling an on/off switch
\begin{center}
\includegraphics[scale=.5]{figures/fa1.eps}
\end{center}
Example of a finite automaton that recognizes the string ``{\tt then}''
\begin{center}
\includegraphics[scale=.5]{figures/fa2.eps}
\end{center}
\end{slide}

\begin{slide}{ Abstractions: Structural representations}
\begin{description}
\item[Grammars:] useful when specifying processes that handle data with a recursive structure. E.g.: mathematical expressions involving variables $x$ and $y$
\begin{center}
\begin{tabular}{l}
<expr> ::= <expr> <op> <expr>  \\
<expr> ::= <var> \\
<op> ::= +$\;|\;$-$\;|\;$*$\;|\;$/\\
<var> ::= x $\;|\;$ y
\end{tabular}
\end{center}



\item[Regular Expressions:] useful when specifying text strings. E.g.: (in Unix-Style notation) Any sequence of letters of the Latin alphabet that starts with a capital letter, and ends in a numerical digit.
\[
[A-Z][a-z]*[0-9]
\]
\end{description}
\end{slide}

\begin{slide}{\large Applications of the Theory are Everywhere}
The theory of computation has many applications in the design and construction of important  kinds of sofware
\begin{itemize}
\item FSMs is used in software for designing digital circuits, and in interactive games.
\item The design of programming languanges and compilers
\item Natural languages are mostly context-free grammars. Speech understanding systems use probabilistic FSMs.
\item Searching for keywords in a file or on the web.
\item Verification of communication protocols.
\item The theory of intractable problems can help us determine whether we are likely to write a program that solves a given problem, or if we have to find a simplified instance of the problem.
\end{itemize}
\end{slide}


\begin{slide}{Central concepts}
\begin{description}
\item[Alphabet:] Finite, nonempty set of symbols, e.g.:
\begin{itemize}
\item binary alphabet $\Sigma = \{0,1\}$
\item the set of all lower case letters $\Sigma=\{a,b,c,\cdots,z\}$
\end{itemize}
\item[String:] Finite sequence of symbols from an alphabet $\Sigma$, e.g.: 001101
\item[Empty String:] \egk\ denotes the string with zero occurrences of symbols from $\Sigma$
\item[Length of String:] Number of positions for symbols in the string. 
\begin{itemize}
\item $|w|$ denotes the length of the string $w$, e.g., $|0110|=4, |\egk |=0$
\end{itemize}
\end{description}
\end{slide}

\begin{slide}{Central concepts (cont.)}
\begin{description}
\item[Powers of an Alphabet:] $\Sigma^k=$ the set of strings of lenght $k$ with symbols from $\Sigma$. E.g.: Given $\Sigma=\{0,1\}$, then  $\Sigma^1=\{0,1\}$, $\Sigma^2=\{00,01,10,11\}$, $\Sigma^0=\{\egk\}$
\item[The set of all strings over $\Sigma$ is denoted] $\Sigma^*=\Sigma^0\cup\Sigma^1\cup\Sigma^2\cup\cdots$  
\item[Also:] 
\[\Sigma^+=\Sigma^1\cup\Sigma^2\cup\Sigma^3\cdots\]
\[\Sigma^*=\Sigma^+\cup\{\egk\}\]
\end{description}
\end{slide}

\begin{slide}{Central concepts (cont.)}
\begin{itemize}
\item {\bf Concatenation}: If $x$ and $y$ are strings, then $xy$ is the string obtained by placing a copy of $y$ immediately after a copy of $x$.

\item Example: $x=01101, y=110, xy= 01101110$
%\begin{center}
%\includegraphics[scale=.4]{figures/cd1.eps}
%\end{center}

\item {\bf Powers of a string}: To concatenate a string with itself many times we use the superscript notation
\[
x^k\mbox{\ is equivalent to\ }\overbrace{xx\cdots x}^k
\]
\item Note the difference (in interpretation) between the notation $x^k$, where $x$ is a string, and  $\Sigma^k$, where $\Sigma$ is a set (an alphabet).
\end{itemize}
\end{slide}

\begin{slide}{And another  concept}
\begin{description}
\item[Languages:] If $\Sigma$ is an alphabet, and $L\subseteq\Sigma^*$, then $L$ is a language
\end{description}
That is, a language is a set of strings. Examples:
\begin{itemize}
\item The set of all legal English words
\item The set of all legal C programs
\item The set of all binary strings with an equal number of 0's and 1's
\[
\{\egk, 01,10, 0011, 0101, 1001,\cdots\}
\]
\end{itemize}
\end{slide}

\begin{slide}{Compact ways to denote languages}
It is common to use a "set-former" to denote a language 
\[
\begin{array}{c}
\{w\;:\;\mbox{something about $w$}\}\\ 
\mbox{which reads: \em "the set of words $w$ such that..."}
\end{array}
\]
Examples
\begin{itemize}
\item \(\{w\;:\; \mbox{$w$ is a valid English word}\}\)
\item \(
\{x01y \;:\; \mbox{$x$ and $y$ are binary strings or \egk}\}
\)
\item \(\{0^n1^n\;:\;n\geq 1\}\)
\end{itemize}
\end{slide}

\begin{slide}{Finite Automata (FA)}
\begin{itemize}
\item FA are simple "machines" that can recognize the first type of languages we will study: {\blue regular languages}
\item A finite automaton has a set of states, and a "control" that moves from state to state in response to external "inputs".
\item Let's create and simulate one in JFLAP
\item There are two major classes of automata: 
\begin{description}
\item[deterministic:] on each input, there is only one state to which the automaton can transition from its current state
\item[nondeterministic:] on some input, there are more than one state to which the automaton can transition from its current state
\end{description}
\end{itemize}
\end{slide}

\begin{slide}{Deterministic Finite Automaton (DFA)}
A DFA is a quintuple
\[
A=(Q,\sg,\delta,q_0,F)
\]
\begin{itemize}
\item $Q$ is a finite set of {\blue states}
\item \sg\ is a finite {\blue alphabet} 
\item $\delta$ is a {\blue transition function} defining the mapping: $Q\times\sg\rightarrow Q$
\item $q_0\in Q$ is the {\blue start state}
\item $F\subseteq Q$ is a set of {\blue final}  states
\end{itemize}
\end{slide}

\begin{slide}{How a DFA processes strings}
\begin{itemize}
\item A DFA is a machine that decides whether or not to {\blue accept} an input string.
\item The {\blue language} of a DFA is the set of all strings it accepts.
\item Given a string $a_1a_2\cdots a_n$
\begin{enumerate}
\item We start out at the initial state, $q_0$
\item We consult  $\delta$ to find the state that the DFA enters, say $\delta(q_0,a_1)=q_1$
\item We process the next input symbol $a_2$, by evaluating $\delta(q_1, a_2)=q_2$
\item We continue, finding states $q_3,q_4,\cdots, q_n$, such that $\delta(q_{i-1},a_i)=q_i$, for each $i$.
\item If $q_n\in F$ then the DFA accepts the string; otherwise it "rejects" the string.
\end{enumerate}
\end{itemize}
\end{slide}

\begin{slide}{Specifying a DFA: example}
\begin{itemize}
\item Suppose you are asked to specify a DFA that accepts all and only the binary strings that start with a 0 and end with a 1.
\item The expression below formally specifies the language $L$ of this particular DFA 
\[
L=\{0x1\;:\; \mbox{$x$ is either a binary string or $\epsilon$}\}
\]
\item Now, let's obtain $\Sigma$, $Q$, $\delta$, $q_0$ and $F$. 
\end{itemize}
\end{slide}

\begin{slide}{Example (cont.)}
%\[
%L=\{0x1\;|\; \mbox{$x$ is a binary string}\}
%\]
\begin{itemize}
\item From the specification of $L$, we obtain $\Sigma=\{0,1\}$
\item To obtain $Q$, and $\delta$, we have to identify the possible states  (and state transitions)
of the scanning process of all strings in $L$.
\[
\begin{array}{l|l}
\delta(q_0,0)=q_1&
\delta(q_0, 1)=q_e\\
\delta(q_1, 0)=q_1&
\delta(q_1,1) = q_2\\
\delta(q_2,0) = q_1&
\delta(q_2,1)=q_2\\
\delta(q_e, 0)=q_e &
\delta(q_e, 1)=q_e
\end{array}
\]

 $Q=\{q_0, q_1, q_2, q_e\}$
\item Inspect $\delta$ to obtain 
\(F=\{q_2\}
\)
\end{itemize}
\end{slide}

\begin{slide}{Simpler notations for DFAs}
In summary, for the DFA seen in the last slides, we have:
\begin{itemize}
\item $Q=\{q_0,q_1, q_2, q_e\}$
\item $\Sigma=\{0,1\}$
\item $q_0$
\item 
\(
\begin{array}{l|l}
\delta(q_0,0)=q_1&
\delta(q_0, 1)=q_e\\
\delta(q_1, 0)=q_1&
\delta(q_1,1) = q_2\\
\delta(q_2,0) = q_1&
\delta(q_2,1)=q_2\\
\delta(q_e, 0)=q_e &
\delta(q_e, 1)=q_e
\end{array}
\)
\item $F=\{q_2\}$
\end{itemize}
There are simpler ways to describe a DFA by a {\blue transition diagram} or a {\blue transition table}.
\end{slide}

\begin{slide}{Exercises}
Give DFAs accepting the following languages over the alphabet $\Sigma=\{0,1\}$
\begin{itemize}
\item $L=\{w : w \mbox{ contains at least two 0's}\}$
\item The set of all strings with three consecutive 0's (not necessarily at the end)
\end{itemize}
\end{slide}

\begin{slide}{Formally defining the language of a DFA}
\begin{itemize}
\item The language $L$ of a DFA is the set of all strings it recognizes.
\item To formally obtain $L$, we extend $\delta$ to operate on strings.
\item We define an {\em extended transition function} $\hat{\delta}$ that returns the state that an automaton reaches when starting in a given state $p$ and processing a sequence of symbols $w$. $\hat{\delta}$ is inductively defined as follows:
\begin{description}
\item[Basis:] $\hat{\delta}(p, \epsilon) = p$
\item[Induction:] suppose $w$ is a string of the form $xa$; i.e., $a$ is $w$'s rightmost symbol and $x$ is the rest of the symbols. Then, $\hat{\delta}(p,w) = \delta(\hat{\delta}(p, x), a)$
\end{description}
\item Now let's see how $\hat{\delta}$ operates.
\end{itemize}
\end{slide}



\begin{slide}{ On how $\hat\delta$ operates}
\begin{itemize}
\item Given the DFA below, verify that $\hat{\delta}(q_0,110010) = q_1$
\item We compute $\hat\delta(q_0,w)$ for each prefix $w$ of 110010.
\[
\begin{array}{l|l}
\begin{array}{r||l|l}
&0&1\\\hline
\rightarrow q_0&q_2 & q_0\\
\star q_1 & q_1 & q_1\\
q_2& q_2& q_1
\end{array}
&
\begin{array}{l}
\hat{\delta}(q_0, \epsilon) = q_0\\
\hat{\delta}(q_0, \epsilon 1) = \delta(\hat{\delta}(q_0, \epsilon), 1) = \delta(q_0, 1) =q_0\\
\hat{\delta}(q_0, 11) = \delta(\hat{\delta}(q_0, 1), 1) = q_0\\
\hat{\delta}(q_0, 110) = \delta(\hat{\delta}(q_0, 11), 0) = q_2\\
\hat{\delta}(q_0, 1100) = \delta(\hat{\delta}(q_0, 110), 0) = q_2\\
\hat{\delta}(q_0, 11001) = \delta(\hat{\delta}(q_0, 1100), 1) = q_1\\
\hat{\delta}(q_0, 110010) = \delta(\hat{\delta}(q_0, 11001), 0) = q_1
\end{array}
\end{array}
\]
\item The language of a DFA $A=(Q, \Sigma, q_0, F)$ is thus defined as
\[
L(A) = \{w\; :\; \hat{\delta}(q_0, w) \in F\}
\]
\end{itemize}
\end{slide}

\begin{slide}{Exercise}
Given the DFA below, use $\hat\delta$ to prove whether the DFAs below accept the string 001110
\[
\begin{array}{r||l|l}
&0&1\\\hline
\rightarrow q_0&q_2 & q_0\\
\star q_1 & q_1 & q_1\\
q_2& q_2& q_1
\end{array}
\]

\[
\begin{array}{r||l|l}
&0&1\\\hline
\rightarrow q_0&q_0 & q_1\\
\star q_1 & q_1 & q_0\\
\end{array}
\]
\end{slide}

\begin{slide}{Exercise}
Let $A$ be a DFA and $a$ a particular input symbol of $A$, such that for all states $q$ of $A$ we have $\delta(q,a)=q$.

Show by induction on $n$ that for all $n\geq0,\hat{\delta}(q,a^n)=q$, where $a^n$ is the string consisting of $n$ a's.
\end{slide}

\begin{slide}{Nondeterministic Finite Automata  (NFA)}
\begin{itemize}
\item NFAs are usually easier to "program" in.
\item Accepts the same type of language accepted by DFAs (i.e., regular languages)
\item An NFA can be in several states at once. Example: An automaton that accepts all and only strings ending in 01.
\begin{itemize}
\item The automaton is able to ``guess'' when the final 01 has begun.
\end{itemize}
\end{itemize}
\begin{center}
\includegraphics[scale=.2]{figures/nfa1.eps}
\end{center}
\end{slide}

\begin{slide}{NFA: formally}
A NFA is a quintuple $A=(Q, \sg,\delta, q_0, F)$, where
\begin{itemize}
\item $Q$ is the set of states
\item \sg\ is the alphabet
\item $\delta$ is the transition function $Q\times\sg \rightarrow R: R\subseteq Q$
\item $q_0\in Q$ is the start state
\item$F \subseteq Q$ is the set of final states.
\end{itemize}
\end{slide}


\begin{slide}{NFA: alternative notations}
\begin{itemize}
\item State diagram:\\  \includegraphics[scale=.33]{figures/nfa3.eps}
\item The quintuple: \(
(\{q_0, q_1, q_2\}, \{0,1\}, \delta, q_0, \{q_2\})
\)
\item State transition table:\\ \includegraphics[scale=.33]{figures/nfa4.eps}
\end{itemize}
\end{slide}

\begin{slide}{Proving if an NFA accepts a string}
Suppose we would like to prove whether the automaton below accepts the string $abccb$
\vspace{1cm}
\begin{center}
\includegraphics[scale=.5]{figures/NFAex1.eps}
\end{center} 

It is apparent that we would need a modified version of $\hat{\delta}$ that works for NFAs...
\end{slide}

\begin{slide}{Extended transition function $\hat{\delta}$}
We inductively define $\hat{\delta}$ that returns the (set of) {\blue states} that a NFA reaches as follows. 
\begin{description}
\item[Basis:] $\hat{\delta}(q, \epsilon)=\{q\}$
\item[Induction:]  Suppose $w=xa$ and  $\hat\delta(q,x)=\{p_1,p_2,\cdots,p_k\}$. 
\begin{minipage}{6cm}
Let
\[
 \bigcup_{i=1}^k\delta(p_i,a)=\{r_1,r_2,\cdots.r_m\}
\]
Then $\hat\delta(q, w)=\{r_1,r_2,\cdots.r_m\}$
\end{minipage}
\begin{minipage}{4cm}
{\blue
Pseudo code:

\(
\begin{array}{l}
r:= \{\ \};\\
\mbox{ for each } p_i\in \{p_1,p_2,\cdots,p_k\} \\
\hspace{1cm}r := r \cup \delta(p_i, a)\\
\hat\delta(p, w)= r;
\end{array}
\)
}
\end{minipage}
%{\small Suppose that $\hat{\delta}(q, x)=\{p_1, p_2, \cdots,p_k\}$ and let $\displaystyle\bigcup_{i=1}^k\delta(p_i,a) = \{r_1,r_2,\cdots, r_m\}$ then $\hat{\delta}(q, w)= \{r_1,r_2,\cdots, r_m\}$}
\end{description}
Formally, the language accepted by $A$ is
\[
L(A) = \{w\;:\; \hat{\delta}(q_0, w)\cap F\neq \emptyset\}
\]
\end{slide}

\begin{slide}{Contrasting $\hat{\delta}$ for DFA and NFA}
\begin{itemize}
\item DFA: 
\begin{description}
\item[Basis:] $\hat{\delta}(p, \epsilon) = p$
\item[Induction:] $\hat{\delta}(p,w) = \delta(\hat{\delta}(p, x), a)$
\end{description}
\[
L(DFA)= \{w\;:\; \hat{\delta}(q_0, w) \in F\}
\]
\item NFA:
\begin{description}
\item[Basis:] $\hat{\delta}(q, \epsilon)=\{q\}$
\item[Induction:] $\hat{\delta}(q, xa) = \bigcup_{p\in\hat\delta(q, x)}\delta(p, a)$

%{\small Suppose that $\hat{\delta}(q, x)=\{p_1, p_2, \cdots,p_k\}$ and let $\displaystyle\bigcup_{i=1}^k\delta(p_i,a) = \{r_1,r_2,\cdots, r_m\}$ then $\hat{\delta}(q, w)= \{r_1,r_2,\cdots, r_m\}$}
\end{description}
\[
L(NFA) = \{w\;:\; \hat{\delta}(q_0, w)\cap F\neq \emptyset\}
\]
\end{itemize}
\end{slide}

\begin{slide}{$\hat{\delta}$ for NFA: example}
Example: Let's compute $\hat{\delta}(q_0, abc)$ for the NFA
\vspace{1cm}
\begin{center}
\includegraphics[scale=.5]{figures/NFAex1.eps}
\end{center} 
(on the board)
\end{slide}


\end{document}

