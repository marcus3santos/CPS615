\documentclass{prosper}%[pdf,azure,slideColor,colorBG]{prosper}
\hypersetup{pdfpagemode=FullScreen}

\usepackage{graphicx}
\usepackage{graphics}
\usepackage{rotating}
\usepackage{amsmath}
\usepackage{epsfig}
\usepackage{verbatim}

\newcommand{\enfa}{{$\epsilon$-NFA}}
\newcommand{\e} {{\mbox{$\epsilon$}}}
\newcommand{\ra}{\mbox{$\;\rightarrow\;$}}
\newcommand{\vb}{\mbox{$\;|\:$}}
\newcommand{\dra}{\mbox{$\;\Rightarrow\;$}}
\newcommand{\cvd}{\mbox{$\;\overset{*}{\vdash}\;$}}
\newcommand{\cavd}[1]{{\mbox{$\;\overset{_*}{\underset{_#1}{\vdash}}\;$}}}
\newcommand{\avd}[1]{\mbox{$\;{\underset{_#1}{\vdash}\;}$}}
\newcommand{\lmd}{\mbox{$\;\underset{lm}{\Rightarrow}\;$}}
\newcommand{\rmd}{\mbox{$\;\underset{rm}{\Rightarrow}\;$}}\newcommand{\pda}[1]{$#1 = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$}
\newcommand{\qed}{{$\;\;\Box$}}

\newcommand{\quiz}[1]{{\hfill \tiny{$_{ #1}$}}}


%\title{Pushdown Automata}
%\author{Marcus V. dos Santos}
%\institution{        Department of Computer Science \\        Ryerson University}

% Optional: text to put in the bottom of each slide.
% By default, the title of the talk will be placed there.
\slideCaption{\textit{Marcus Santos, RU}}

\begin{document}

\begin{slide}{Procedural descriptors for CFLs}
\begin{itemize}
\item In our study of regular languages  we saw that  we can describe such languages ``procedurally'' using a finite automaton (DFA, NFA, e-NFA), or ``declaratively'' using a regular expression.
\item In our study of context free languages, we first learned how we can use CFGs to ``declaratively'' describe those languages.
\item Today we will learn how we can specify machines called {\blue Pushdown Automata} that describe CFLs ``procedurally''.
\end{itemize}
\end{slide}

%\maketitle
\begin{slide}{Pushdown Automata}
%\begin{center}
%\includegraphics[scale=.3]{figures/pda1.eps}
%\end{center}
\begin{itemize}
\item A pushdown automata (PDA) is essentially an \e-NFA with a stack on which it can store symbols.
\item PDA can only access information on the stack in a last-in-first out way. 
\item There are two versions of  a PDA, and they differ on how a PDA accepts a string, i.e.,
\begin{itemize}
\item acceptance by accepting state, or 
\item acceptance by empty stack.%\item Real computers, 
\end{itemize}
\end{itemize}
\end{slide}

\begin{slide}{PDA informally}
\begin{center}
\includegraphics[scale=.4]{figures/pda1.eps}
\end{center}
\begin{itemize}
\item The finite control reads one symbol at a time from the input, and observes the symbol on top of the stack.
\item It bases its transitions on {\blue its state}, {\blue the input symbol}, and {\blue the symbol on top of the stack}.
\item On a transition, the PDA:
%\begin{minipage}{6cm}
\begin{enumerate}
\item Consumes an input symbol. 
\item Goes to a new state (or stays in the old). 
\item Replaces the top of the stack by a string
\end{enumerate}
\end{itemize}
\end{slide}

\begin{slide}{An informal example}
\begin{itemize}
\item Consider the grammar $P\ra aPb\vb \e$, and its language \[
L=\{a^nb^n:n\geq 0\}\] 

\item Suppose you are a simple machine whose only memory is a stack.

\item How would you recognize strings in this language?
\end{itemize}

\end{slide}

\begin{slide}
{An informal example}
Consider the grammar $P\ra aPb\vb \e$, and its language \[
L=\{a^nb^n:n\geq 0\}\] 
A PDA for $L$ has 3 states and operates as follows:
\begin{enumerate}
\item Keeps reading $a$s and pushing them onto the stack until it finds a $b$, which makes it pop an $a$ from the stack and transition to the next state.
\item Keeps reading $b$s and popping as many $a$s; if the ``start symbol''  is on top of the stack, then accepts.
\end{enumerate}
\end{slide}

\begin{slide}{PDA, formally}
A PDA is a 7-tuple $P=(Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$, where:
\begin{itemize}
\item $Q, \Sigma, q_0,$ and $F$, are our old friends;
\item $\Gamma$ is the stack alphabet;
\item $Z_0$ is the start symbol;
\item $\delta$ is the transition function %$\delta: Q\times\Sigma\times\Gamma \longrightarrow {\cal P}(Q\times \Gamma)$, e.g., 
$\delta(q, a, X)=\{(p,\gamma),\cdots\}$, where:
\begin{itemize}
\item $q$ is  a state, $a$ is an input symbol, $X$ is a stack symbol
\item $p$ is a state, and $\gamma$ is the string of stack symbols that {\blue replaces $X$} on top of the stack. E.g.:
\[
\begin{array}{l}
\delta(q, a ,X) =\{(p,\epsilon)\} \mbox{ Stack is popped.}\\
\delta(q, a, X)=\{(p, X)\} \mbox{ Stack is unchanged.}\\
\delta(q, a, X)=\{(p, YZ)\} \mbox{ $X$ replaced by $Z$; $Y$ pushed.}\\
\end{array}
\]
\end{itemize}
\end{itemize}
\end{slide}

\begin{slide}{A Graphical notation for PDAs}
In the notation used in our textbook, a transition diagram for a  PDA consists of the following elements:
\begin{itemize}
\item Like in finite automata, nodes represent states, and the start state and accept states are denoted as usual.
\item Arcs correspond to transitions of the PDA as follows:
\begin{center}
 \includegraphics[scale=.5]{figures/pdatrans.eps} means $(p, \alpha)  \in \delta(q, a, X)$
 \end{center}
\item Conventionally, $Z_0$ or $Z$ denote the start symbol for the stack.
\end{itemize}
Let's obtain a PDA for the language $\{a^nb^n, n\geq 0\}$ using JFLAP.
\end{slide}


\begin{slide}{A Nondeterministic PDA}
Consider the grammar $P\ra 0P0\vb1P1\vb \e$, and its language \[
L=\{ww^R:w\in\{0,1,\}^*\}\] 

A PDA for $L$ has three states and operates as follows:
\begin{enumerate}
\item Guesses that it is reading $w$. Stays in state $q_0$, and pushes the input symbol onto the stack. 
\item  Guesses that it is in the middle of $ww^R$, {\em i.e.}, $w$ would be on the stack. Goes spontaneously to state $q_1$. 
\item It is  now reading the head of $w^R$. Compares it to the top of the stack. If they match, pops the stack, and remains in state $q_1$. 
If they don't match, goes to sleep. 
\item If the stack is empty, goes to state $q_2$ and accepts. 
\end{enumerate}
\end{slide}



\begin{slide}{PDA for $L=\{ww^R:w\in\{0,1,\}^*\}$}
\begin{center}
\includegraphics[scale=.2]{figures/pda2.eps}
\end{center}

\[
P=(\{q_0, q_1, q_2\}, \{0,1\}, \{0, 1, Z_0\}, \delta, q_0, Z_0, \{q_2\}).
\] where $\delta$ is given by the table below
\begin{center}
\includegraphics[scale=.4]{figures/pda3.eps}
\end{center}
We assume the PDA accepts a string by consuming it and entering an accepting state.
\end{slide}

\begin{slide}{PDA: exercise}
Design a PDA that recognizes the language
\[
\{a^ib^jc^k:i,j,k\geq 1\mbox{ and }i=j\mbox{ or }i=k\}
\]
Provide a CFG for the language.
\end{slide}

\begin{slide}{PDA: exercise}
Design a PDA that recognizes the language
\[
\{w: w\; \mbox{contains as many 1s as 0s}\}
\]
Provide a CFG for the language.
\end{slide}

\begin{slide}{PDA: exercise}
Design a PDA that recognizes the language
\[
\{w: w\; \mbox{contains more 1s than 0s}\}
\]
Provide a CFG for the language.
\end{slide}


\begin{slide}{Instantaneous Descriptions (IDs)}
\begin{itemize}
\item $(q, w, \gamma)$ is an {\blue Instantaneous Description}  of a PDA  configuration.
\begin{itemize}
\item $q$ is the current state
\item $w$ is the remaining input
\item $\gamma$ is the contents the stack
\end{itemize}
\item Using IDs to represent a {\blue computation step by a PDA}: suppose  \includegraphics[scale=.5]{figures/pdatrans.eps}, then for all strings $w$, \[(q, aw, X\beta)\vdash (p, w, \alpha \beta)\]

%\[\mbox{Suppose }(p, \alpha)  \in \delta(q, a, X)\mbox{, then for } (q, aw, X\beta)\vdash (p, w, \alpha \beta)\] 
%\item \cvd is the  closure of $\vdash$, meaning ``zero or more computation steps (moves) of the PDA''.

\end{itemize}
\end{slide}

\begin{slide}{Computation as a sequence of IDs}
Example: Starting from the ID $(q, 010, Z)$, show all the reachable ID's for the PDA below.
\begin{center}
\includegraphics[scale=.7]{figures/pda2new.eps}
\end{center}
\end{slide}

\begin{comment}
\begin{slide}{Some properties of PDA}\label{sl:prop}
\begin{itemize}
\item If an ID sequence is a legal computation for a PDA, then so is the sequence obtained by adding an additional string to the second and/or third component. Formally: $\forall w \in\Sigma^*, \beta \in\Gamma^*$ :
\[
\mbox{if }(q, x, \mbox{\red \underline{$\alpha$}})\cvd(p, y, \mbox{\red \underline{$\beta$}}) \mbox{, then }(q, xw, \mbox{\red \underline{$\alpha\gamma$}} )\cvd(p, yw, \mbox{\red\underline{ $\beta\gamma$}})
\]
\item  If an ID sequence is a legal computation 
for a PDA, and some tail of the input is 
not consumed, then removing this tail from 
all ID's result in a legal computation sequence. 
\[
\mbox{if }(q, {\red\underline{ xw}}, \alpha)\cvd(p, {\red\underline{ yw}}, \beta)  \mbox{, then }(q, {\red \underline{x}}, \alpha )\cvd(p, {\red \underline{y}}, \beta)
\]
\end{itemize}
\end{slide}
\end{comment}



\begin{slide}{The languages of a PDA}
\begin{itemize}
\item For a DFA $D$, we saw that $L(D)=\{w: \hat{\delta}(q_0, w)\in F\}$, where $F$ is the set of accepting states.
\item For PDAs, there are two {\blue equivalent} approaches to define the languages they accept:
\begin{itemize}
\item Acceptance by final state
\item Acceptance by empty stack
\end{itemize}
%\item Notice, however, that for a given PDA $P$, the languages that $P$ accepts by final state and by empty stack are usually different.
\end{itemize}
\end{slide}
 
 \begin{slide}{Acceptance by final state}
\begin{itemize}
\item  Let \pda{P}\ be a PDA. 
\item The language accepted by $P$ by {\blue final state} is
 \[
 L_{f}(P ) = \{w : (q_0, w, Z_0)\cvd(q,{\red \e},\alpha), {\red q \in F} \}.
\]
Notice:
\begin{itemize}
\item $P$ consumes $w$ completely.
\item $P$ halts in an accepting state.
\item The stack might not be emptied.
\end{itemize}
\end{itemize}
\end{slide}


\begin{slide}{Acceptance by empty stack}
\begin{itemize}
\item Let \pda{P} be a PDA.
\item The language accepted by $P$ by {\blue empty stack} is
\[
L_{e}(P)=\{w:(q_0,w,Z_0)\cvd (q, {\red \e}, {\red \e})\}
\]
Notice:
\begin{itemize}
\item  $q$ can be any state
\item $P$ at the same time consumes $w$ and empties the stack
\item $F$ is redundant in the definition of the PDA and is usually left off in the representation.
\end{itemize}
\end{itemize}
\end{slide}

\begin{slide}{From Empty Stack to Final State}
{\bf Theorem}: If $P_N=(Q, \Sigma, \Gamma, \delta, q_0, Z_0)$ accepts by empty stack, then $\exists$ PDA $P_F$ that accepts by final state such that $L_e(P_N)=L_f(P_F)$ .
\begin{itemize}
\item The idea behind the proof of this theorem is to build a PDA $P_F$ that simulates $P_N$ and accepts if $P_N$ empties the stack.
\end{itemize}
\begin{minipage}{5cm}
\includegraphics[scale=.3]{figures/pda5.eps}
\end{minipage}
\begin{minipage}{6cm}
\begin{itemize}
\item $\delta_F(p_0,\epsilon,X_0)=\{(q_0, Z_0X_0)\}$
\item Keep all state transitions of $P_N$.
\item Add transitions $\delta_F(q, \epsilon, X_0)=\{(p_f, \epsilon)\}$ for every state $q\in Q$
\end{itemize}
\end{minipage}
\[
(p_0,w,X_0)\avd{{P_F}}(q_0,w,Z_0X_0)\cavd{{P_N}}(q,\e,X_0)\avd{{P_F}}(p_f,\e,\e)
\]
\end{slide}


\begin{slide}{From Final State to Empty Stack}
{\bf Theorem}: If \pda{P_F} accepts by final state, then $\exists$ PDA $P_N$ that accepts by empty stack such that $L_f(P_F)=L_e(P_N)$.
\begin{itemize}
\item The idea behind the proof of this theorem is to build a PDA $P_N$ that simulates $P_F$ and accepts if $P_F$ accepts by final state.
\end{itemize}
\begin{minipage}{5cm}
\includegraphics[scale=.3]{figures/pda8.eps}
\end{minipage}
\begin{minipage}{6cm}
\begin{itemize}
\item $\delta_N(p_0,\epsilon,X_0)=\{(q_0, Z_0X_0)\}$
\item Keep all state transitions of $P_F$.
\item Add transitions $\delta_N(q, \epsilon, X)=\{(p_f, \epsilon)\}$ for every state $q\in F$ and symbol $X\in\Gamma\cup\{X_0\}$.
\end{itemize}
\end{minipage}
\end{slide}

\begin{comment}
\begin{slide}{PDA conversion: example}
Consider the PDA $P$ below and its language $L_f(P)$. Convert $P$ to another PDA $P_1$ that accepts by empty stack such that $L_f(P)=L_e(P_1)$
\begin{center}
\includegraphics[scale=.7]{figures/pda2new.eps}
\end{center}
\end{slide}
\end{comment}

\begin{slide}{Equivalence of PDAs and CFGs}
\begin{itemize}
\item We shall see that PDAs and CFGs are equivalent in power: both represent the same class of languages.
\item We will do that by showing how to obtain a PDA from a CFG, and vice-versa.
\item Our objective is to prove the following theorem:
{\em \begin{quote}
A language is context-free {\large\blue iff} some PDA recognizes it.
\end{quote}}
Therefore, two lemmas:
\begin{itemize}
\item[{\blue\bf L1}:] If a language is context-free, then some PDA recognizes it.
\item[{\blue\bf L2}:] If a PDA recognizes some language, then it is context-free.
\end{itemize}
\end{itemize}
\end{slide}

\begin{slide}{Proving L1}
\begin{itemize}
\item Proof idea: show how to convert a CFG $G$ to a PDA $P$.
\item We will design $P$ to simulate leftmost derivations of strings according to $G$.
\item The stack will contain the strings of the derivations.
\end{itemize}
The derivation of the string $aaabbb$ according to the grammar below gives us a hint on the operation of the PDA.
\[
\begin{array}{l}
A\ra aAb \vb \e\\\ \\
A\dra aAb\dra aaAbb \dra aaaAbbb \dra aaabbb
\end{array}
\]
%Now, let's see on the board how a PDA would accept this string by empty stack. And as we do it, we shall design the PDA.
\end{slide}

\begin{comment}
\item The PDA's nondeterminism will come in handy, as it allows it to guess the sequence of correct substitutions.
\item $P$'s design sketch: $P$ will push on the stack left-sentential forms of $G$; and it will go through these sentential forms, making one substitution after another. Eventually it {\blue may} arrive at a configuration (a string) that contains only terminals. Then $P$ accepts if this string matches $w$.
\end{itemize}
\end{slide}
\end{comment}

\begin{slide}{Proof idea of L1 (cnt.)}
This is how a PDA would accept a string (by empty stack) based on the grammar rules:
\begin{itemize}
\item Place the start variable on the stack.
\item Repeat the following steps:
\begin{enumerate}
\item[a)] If the top of the stack is a variable $A$, nondeterministically select a rule $A \ra \gamma$ and substitute $A$ on the stack by $\gamma$.
\item[b)] If the top of the stack is a terminal symbol $a$, read the next symbol from the input and compare it to $a$. If they don't match, reject this branch of the nondeterminism.
%\item[c)] If the top of the stack is P's start symbol, enter the accept state. Doing so accepts the input if it has all been read.
\end{enumerate}
\end{itemize}
\end{slide}

\begin{slide}{Obtaining a PDA from a CFG}
\begin{enumerate}
\item For each variable $A$ in grammar $G$,
\[
\delta(q, \epsilon, A)=\{(q, \beta)\;|\;a\rightarrow \beta\mbox{ is a production of $G$}\}
\]
\item For each terminal $a$, $\delta(q, a, a)=\{(q, \epsilon)\}$.
\end{enumerate}
\begin{minipage}{6cm}
Example: 
\[
A\ra aAb | \epsilon
\]
\end{minipage}
\begin{minipage}{5cm}
\begin{center}
\includegraphics[scale=.6]{figures/cfg-PDA.eps}
\end{center}
\end{minipage}
Use IDs to show that the PDA accepts $aabb$ by empty stack.
\end{slide}


\end{document}

begin{comment}
\begin{slide}{Proving $x\in L(P) \Leftarrow x=ww^R$}
\begin{center}
\includegraphics[scale=.4]{figures/pda2.eps}
\end{center}
\begin{itemize}
\item We assume $x=ww^R$. Then, we can see (by inspecting the PDA) that the following is a legal computation sequence.
\[
\begin{array}{l}
(q_0, ww^R, Z_0) \cvd(q_0, w^R, w^RZ_0)\vdash(q_1, w^R, w^RZ_0)\cvd\\(q1,\e, Z_0)\vdash(q_2,\e, Z_0)
\end{array}
\]
\end{itemize}
\end{slide}
 
\begin{slide}{Proving $x\in L(P) \dra x=ww^R$}
\begin{center}
\includegraphics[scale=.4]{figures/pda2.eps}
\end{center}
\begin{itemize}
\item Observe that the only way the PDA can enter 
$q_2$ is if it is in state $q_1$ with an empty stack. 
\item Then, we'll show by induction in $|x|$ that 
\[
(q_0, x, \alpha)\cvd(q_1,\e, \alpha) \dra x = ww^R
\]
{\bf Basis:} If $x=\e$ then $x$ is a palindrome. \qed
 \end{itemize}
 \end{slide}
 
\begin{slide}{Proving {\small $(q_0, x, \alpha)\cvd(q_1,\e, \alpha) \dra x = ww^R$}}

{\bf Induction:} Suppose $x = a_1a_2\cdots a_n$, $n > 0$, and the IH holds for shorter strings. There are two moves for the PDA from the ID $(q_0,x, \alpha)$
\begin{itemize}
\item The spontaneous $(q_0, x, \alpha)\vdash(q_1, x, \alpha)$.  Now $(q1, x, \alpha)\cvd(q_1,\e, \beta)$ implies that $\beta< \alpha$, which implies $\beta\neq \alpha$. 
\item Loop and push. A computation ending in $(q_1, \e, \alpha)$ would look like this:
\(
(q_0, a_1a_2\cdots a_n, \alpha)\vdash(q_0, a_2\cdots a_n, a_1\alpha)\vdash\cdots\vdash
(q_1, a_n, a_1\alpha)\vdash(q_1,\e, \alpha)
\). 

Thus, $a_1=a_n$ and $(q_0, a_2 \cdots a_n, a_1\alpha)\cvd(q_1, a_n, a_1\alpha)$.

From theorem in Slide \ref{sl:prop}, we can remove $a_n$. Therefore, $(q_0, a_2\cdots a_{n-1}, a_1\alpha)\cvd(q_1, \e, a_1\alpha)$.
Then, by IH $a_2\cdots a_{n-1}=yy^R$. Then $x=a_1yy^Ra_n$ is a palindrome.\qed
\end{itemize}
\end{slide}
\end{comment}

